# LiteLLM Environment Configuration
# Copy this file to .env and update with your values

# API Keys for various LLM providers
# Add the keys for the providers you want to use

# OpenAI
# OPENAI_API_KEY=your-openai-api-key

# Anthropic
# ANTHROPIC_API_KEY=your-anthropic-api-key

# Azure OpenAI (Required for config.yaml)
AZURE_API_KEY=your-azure-api-key
AZURE_API_BASE=https://your-resource.openai.azure.com/
AZURE_API_VERSION=2024-02-15-preview

# AWS S3 for Logging (Required for config.yaml)
# For local development with MinIO (default setup):
AWS_ACCESS_KEY_ID=minioadmin
AWS_SECRET_ACCESS_KEY=minioadmin
S3_BUCKET_NAME=litellm-logs
S3_REGION_NAME=us-east-1
S3_PATH_PREFIX=litellm-logs/
AWS_ENDPOINT_URL=http://minio:9000
# Note: For production with AWS S3, update the credentials above and remove AWS_ENDPOINT_URL

# Google AI
# GEMINI_API_KEY=your-gemini-api-key

# Cohere
# COHERE_API_KEY=your-cohere-api-key

# Replicate
# REPLICATE_API_KEY=your-replicate-api-key

# Hugging Face
# HUGGINGFACE_API_KEY=your-huggingface-api-key

# Master Key for LiteLLM Proxy (set this to secure your proxy)
# LITELLM_MASTER_KEY=sk-1234

# Database Configuration (already set in docker-compose.yml)
# DATABASE_URL=postgresql://llmproxy:dbpassword9090@db:5432/litellm

# UI Configuration
# UI_USERNAME=admin
# UI_PASSWORD=admin

# Logging
# SET_VERBOSE=True